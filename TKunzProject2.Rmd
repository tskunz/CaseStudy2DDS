---
title: "Trevor_Kunz_Case_Study2"
author: "TK"
date: "2023-11-15"
output: html_document
---

Link to Presentation:
https://youtu.be/M3x2dqi9RGY

Link to Rshiny App:
https://tkunz.shinyapps.io/fritolayattritionshiny/


Administrative loading packages and requisite files for the analysis.
```{r}
#Load necessary packages
library(RCurl)
library(tidyverse)
library(stats)
library(caret)
library(e1071)
library(class)
library(pROC)

# Load in data set from Amazon S3
cs2data = read.csv("https://s3.us-east-2.amazonaws.com/msds.ds.6306.2/CaseStudy2-data.csv", stringsAsFactors = TRUE)

# Load in classification competition set
compClassData = read.csv("https://msdsds6306.s3.us-east-2.amazonaws.com/CaseStudy2CompSet+No+Attrition.csv", stringsAsFactors = TRUE)

# load in regression competition set
compSalData = read.csv("https://msdsds6306.s3.us-east-2.amazonaws.com/CaseStudy2CompSet+No+Salary.csv")
```


Creating binary fields to assist with the classification models, and data visualization.
```{r}
#creating a binary fields to assist with classification.
cs2data$AttrBin = ifelse(cs2data$Attrition == "Yes", 1, 0)
cs2data$MF = ifelse(cs2data$Gender == "Male", 1, 0)
cs2data$OT = ifelse(cs2data$OverTime == "Yes", 1, 0)
cs2data$o18 = ifelse(cs2data$Over18 == "Y", 1, 0)
cs2data$Married = ifelse(cs2data$MaritalStatus == "Married", 1, 0)
cs2data$Divorced = ifelse(cs2data$MaritalStatus == "Divorced", 1, 0)
cs2data$Travel = as.numeric(cs2data$BusinessTravel) - 1
cs2data$RND = ifelse(cs2data$Department == "Research & Development", 1, 0)
cs2data$Sales = ifelse(cs2data$Department == "Sales", 1, 0)
cs2data$U30 = ifelse(cs2data$Age < 30, 1, 0)
cs2data$U35 = ifelse(cs2data$Age < 35, 1, 0)
cs2data$U40 = ifelse(cs2data$Age < 40, 1, 0)
cs2data$O45 = ifelse(cs2data$Age > 45, 1, 0)
cs2data$Attrition = relevel(cs2data$Attrition, ref = "Yes")
cs2data$L10 = ifelse(cs2data$TotalWorkingYears <= 10, 1, 0)

cs2data %>% ggplot(aes(x =  EnvironmentSatisfaction, y = OT, color = Attrition)) + geom_jitter(width =.1, length = .1)
```


Running Correlation data to assist with variable selection for the classification and regression models.


```{r}
#Correlation Data to assist in variable selection
sel = cs2data[,c("AttrBin", "Age", "Travel", "DailyRate", "RND", "Sales", "DistanceFromHome", "Education", "EnvironmentSatisfaction", "EmployeeNumber", "HourlyRate", "MF", "JobInvolvement", "JobLevel", "JobSatisfaction", "Married", "Divorced", "MonthlyIncome", "MonthlyRate", "NumCompaniesWorked",  "OT", "PercentSalaryHike", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel", "TotalWorkingYears", "TrainingTimesLastYear", "WorkLifeBalance", "YearsAtCompany", "YearsInCurrentRole", "YearsSinceLastPromotion", "YearsWithCurrManager", "U40", "U30", "U35", "O45")]
corrData = cor(sel)

#Attrition Correlation Data using the Binary Attrition Field
attrCorrData = corrData["AttrBin",]
attrCorrData

# Salary Correlation Data
salCorrData = corrData["MonthlyIncome",]
salCorrData
```

After the model runs the initial KNN with a 50% threshold, the threshold will be reset to be more sensitive as which employees are leaving as well as false positives and negatives to identify employees at risk of attrition. Once employees with attrition risk are identified, we recommend reviewing whether they are high performing employees to take actions to retain, or low performers where voluntary attrition is preferable as the company will not incur the expense of termination.

This model also runs to find the optimal K value for the KNN model. Over 100 iterations with k = 3 to 25 for each of the odd k values (odd k values are easier to classify tie breakers). K = 3 was the most accurate model, see the results below:
selected_k_values
 3  5  7  9 11 13 15 17 19 21 23 25 
39 29  7  6  6  2  3  3  1  1  2  1 

```{r}
# set counter for iterations
iter = 100

# Add variables to measure performance of the model across iterations.
accKNNoriginal = matrix(nrow = iter)
accKNNThreshold = matrix(nrow = iter)
sensKNNoriginal = matrix(nrow = iter)
sensKNNThreshold = matrix(nrow = iter)
specKNNoriginal = matrix(nrow = iter)
specKNNThreshold = matrix(nrow = iter)
selected_k_values = numeric(iter)

# Range of k values to find the optimal K value. Using only odd numbers for tie breakers
k_values = seq(3, 25, by = 2)

# create a loop to iterate through the model
for (s in 1:iter) {
  
  # set seed to s generate replicable for each iteration to measure model performance
  set.seed(s)
  
  # Set training and test data sets for the data
  trainIndices = sample(seq(1:length(cs2data$Attrition)), round(.7*length(cs2data$Attrition)))
  trainData = cs2data[trainIndices,]
  testData = cs2data[-trainIndices,]

  # Set variables for the best K value and Accuracy metric
  best_k = NULL
  best_accuracy = 0
  
  # Iterate through the range of k values
  for (k in k_values) {
    
    # KNN with variables most correlated with Attrition
    classificationsKNN = knn(trainData[, c("OT", "U30", "JobLevel", "JobInvolvement")],
                              testData[, c("OT", "U30", "JobLevel", "JobInvolvement")],
                              trainData$Attrition, prob = TRUE, k = k)
    
    # Create confusion matrix for the given iteration
    KNNCM = confusionMatrix(classificationsKNN, testData$Attrition)
    
    # Store model performance results
    accuracy = KNNCM$overall["Accuracy"]
    
    # Check if the current k gives better accuracy than other stored K values
    if (accuracy > best_accuracy) {
      best_accuracy = accuracy
      best_k = k
    }
  }
  
  # Display the selected k value
  #cat("Iteration:", s, "Selected k:", best_k, "\n")
  selected_k_values[s] = best_k
  
  # Use the best k found in the grid search
  classificationsKNN = knn(trainData[, c("OT", "JobInvolvement", "U30", "JobLevel")], 
                            testData[, c("OT", "JobInvolvement", "U30", "JobLevel")], 
                            trainData$Attrition, prob = TRUE, k = best_k)
  
  # Create confusion matrix for the given iteration
  KNNCM = confusionMatrix(classificationsKNN, testData$Attrition)
  
  # Store model performance results for the original k
  accKNNoriginal[s] = KNNCM$overall[c("Accuracy")]
  sensKNNoriginal[s] = KNNCM$byClass[c("Sensitivity")]
  specKNNoriginal[s] = KNNCM$byClass[c("Specificity")]

    # Get probability of Attrition
  probAttr = ifelse(classificationsKNN == "Yes", attributes(classificationsKNN)$prob, 1- attributes(classificationsKNN)$prob)
  
  # Resetting the threshold to .2, as it was a little more accurate across the iterations at .2 than the absolute percentage of attrition / (attrition + not attrition) or 140/(140 + 730). Then continued to adjust to get within 60% sensitivity and specificity
  NewClassification = ifelse(probAttr > .1519, "Yes", "No")
  NC = table(NewClassification, testData$Attrition)
  
  CM_AttrNC = confusionMatrix(table(relevel(as.factor(NewClassification), ref = "Yes"), testData$Attrition), mode = "everything")
  
  # Print results of the confusionMatrix
#  cat("Thresholded k:", best_k, "\n")
#  CM_AttrNC
  
  # Store model performance results for the thresholded k
  accKNNThreshold[s] = CM_AttrNC$overall[c("Accuracy")]
  sensKNNThreshold[s] = CM_AttrNC$byClass[c("Sensitivity")]
  specKNNThreshold[s] = CM_AttrNC$byClass[c("Specificity")]
}

# printing out which k value is selected to determine the best k
table(selected_k_values) #3 is usually the best k.

```

The below model uses K-NN k = 3 as it was found to be the best K value and the same input variables. The competition set will be derived from the below code using the same threshold, variables, and k = 3.


```{r}

# set counter for iterations
iter = 100

# Add variables to measure performance of the model across iterations.
accKNNoriginal = matrix(nrow = iter)
accKNNThreshold = matrix(nrow = iter)
sensKNNoriginal = matrix(nrow = iter)
sensKNNThreshold = matrix(nrow = iter)
specKNNoriginal = matrix(nrow = iter)
specKNNThreshold = matrix(nrow = iter)

# create a loop to iterate through the model
for (s in 1:iter){
  
  #set seed to s generate reproducibility for each iteration to measure model performance
  set.seed(s)
  
  # Set training and test data sets for the data
  trainIndices = sample(seq(1:length(cs2data$Attrition)),round(.70*length(cs2data$Attrition)))
  trainData = cs2data[trainIndices,]
  testData = cs2data[-trainIndices,]

  #KNN K = 3 with variables most correlated with Attrition
  classificationsKNN3 = knn(trainData[,c("OT", "JobInvolvement", "U30", "JobLevel")], testData[,c("OT","JobInvolvement", "U30", "JobLevel")], trainData$Attrition, prob = TRUE,  k = 3)
  
  #create confusion matrix for the given iteration
  KNN3CM = confusionMatrix(classificationsKNN3, testData$Attrition)

  # store model performance results  
  accKNNoriginal[s] = KNN3CM$overall[c("Accuracy")]
  sensKNNoriginal[s] = KNN3CM$byClass[c("Sensitivity")]
  specKNNoriginal[s] = KNN3CM$byClass[c("Specificity")]
  
  # Get probability of Attrition
  probAttr = ifelse(classificationsKNN3 == "Yes", attributes(classificationsKNN3)$prob, 1- attributes(classificationsKNN3)$prob)
  
  # Lowering the threshold to .1591 which is the total of the 140 attrition records divided by the 870 total records. Lowering the threshold will increase the sensitivity (number of true positives), but lower the specificity (number of true negatives)
  NewClassification = ifelse(probAttr > .125, "Yes", "No")
  NC = table(NewClassification, testData$Attrition)
  
  CM_AttrNC = confusionMatrix(table(relevel(as.factor(NewClassification), ref = "Yes"), testData$Attrition), mode = "everything")
  
  # Print results of the confusionMatrix
  # CM_AttrNC
  
  # store model performance results  
  accKNNThreshold[s] = CM_AttrNC$overall[c("Accuracy")]
  sensKNNThreshold[s] = CM_AttrNC$byClass[c("Sensitivity")]
  specKNNThreshold[s] = CM_AttrNC$byClass[c("Specificity")]
}


# summary of model performance
print("Accuracy at K = 3")
summary(accKNNThreshold)
print("Sensitivity at K = 3")
summary(sensKNNThreshold)
print("Specificity at K = 3")
summary(specKNNThreshold) 

# sum of how many times Sensitivity is below the threshold
sum(sensKNNThreshold < .6)
sum(sensKNNThreshold < .6) / iter

# sum of how many times specificity is below the threshold
sum(specKNNThreshold < .6)
sum(specKNNThreshold < .6) / iter

```
The below regression model was created as an alternate means to classify the predicted Attrition model.

Linear regression was used to calculate the percentage of AttrBin (the Binary Variable created using the Attrition Data with 1 = Attrition, 0 = Not Attrition). Then the (Attrition / Total Records) Threshold was used to predict Attrition. The major difference in the results of the two models is K-NN has better Specificity while the Linear Regression Model has better Sensitivity. This provides more evidence to "All models are wrong, some are useful".

Best seed is 76

```{r}
# Using a regression model to predict attrition using the binary variable AttrBin

# Set iteration counter
iter = 100

# create matrices to store the results
regAcc = matrix(nrow = iter)
regSens = matrix(nrow = iter)
regSpec = matrix(nrow = iter)

# Create Loop to measure across multiple iterations for model validation
for(s in 1:iter){ 
    # set seed to s generate replicable for each iteration to measure model performance
    set.seed(s)
      
    # Set training and test data sets for the data
    trainIndices = sample(seq(1:length(cs2data$Attrition)),round(.7*length(cs2data$Attrition)))
    trainData = cs2data[trainIndices,]
    testData = cs2data[-trainIndices,]
    
    # Create regression model using the test and training data
    attrModel = lm(AttrBin ~ OT + JobLevel + JobInvolvement + U30, data = trainData)
    attrPreds = predict(attrModel, newdata = testData)

  # Setting a variable to predict attrition if the predicted value from the linear regression model is greater than the 140 / 870 or attrition / total records. This is equal to approximately 16%, and then tweaking to adjust the sensitivity and specificity. .2 was found to be the best threshold.
  attrClassificationPreds = ifelse(attrPreds >= .2, "Yes", "No")
  testData$attrPreds = attrPreds
  # set to a factor to store the results
  attrClassificationPreds = factor(attrClassificationPreds, levels = c("Yes", "No"))
  # create a confusionMatrix
  CMAttrReg = confusionMatrix(attrClassificationPreds, testData$Attrition)
  
  # store the results of the model
  regAcc[s] = CMAttrReg$overall[c("Accuracy")]
  regSens[s] = CMAttrReg$byClass[c("Sensitivity")]
  regSpec[s] = CMAttrReg$byClass[c("Specificity")]
}


# print results
print("Accuracy")
summary(regAcc)
print("Sensitivity")
summary(regSens)
print("Specificity")
summary(regSpec)
```


Model Comparison
```{r}
NewClassification = factor(NewClassification, levels = c("Yes", "No"))
# Set up tables to compare the model predictions
compTable = table(NewClassification, attrClassificationPreds)
compCMTable = confusionMatrix(compTable)
compCMTable
```



```{r}
# Competition Classification Model

# Creating the same fields used in cs2data necessary to run the model.
compClassData$MF = ifelse(compClassData$Gender == "Male", 1, 0)
compClassData$OT = ifelse(compClassData$OverTime == "Yes", 1, 0)
compClassData$Married = ifelse(compClassData$MaritalStatus == "Married", 1, 0)
compClassData$Divorced = ifelse(compClassData$MaritalStatus == "Divorced", 1, 0)
compClassData$U30 = ifelse(compClassData$Age < 30, 1, 0)
compClassData$U35 = ifelse(compClassData$Age < 35, 1, 0)
compClassData$Sales= ifelse(compClassData$Department == "Sales", 1, 0)


# Set seed for reproducibility - Best seed was 76
set.seed(76)

# Set training and test data sets for the data
trainIndices = sample(seq(1:length(cs2data$Attrition)),round(.7*length(cs2data$Attrition)))
trainData = cs2data[trainIndices,]
testData = cs2data[-trainIndices,]

#KNN K = 3 with variables most correlated with Attrition
compKNN3 = knn(cs2data[,c("OT", "JobInvolvement", "JobLevel", "U30")], compClassData[,c("OT","JobInvolvement", "JobLevel", "U30")], cs2data$Attrition, prob = TRUE,  k = 3)

probCompAttr = ifelse(compKNN3 == "Yes", attributes(compKNN3)$prob, 1 - attributes(compKNN3)$prob)

# Lowering the threshold to .125, which is best threshold found when testing the models above.
compNewKNN = ifelse(probCompAttr > .125, "Yes", "No")
compClassData$AttKNN = compNewKNN
compClassData$AttKNN = factor(compClassData$AttKNN, levels =  c("Yes", "No"))

summary(compClassData$AttKNN)

#Add in Regression Model

attrCModel = lm(AttrBin ~ OT + JobInvolvement+ U30 + JobLevel, data = cs2data)
attrCPreds = predict(attrCModel, newdata = compClassData)
compClassData$RegPreds = attrCPreds

# Setting a variable to predict attrition if the predicted value from the linear regression model is greater than .2, the threshold used in the test and training models.
attrClassPreds = ifelse(attrCPreds >= .20, "Yes", "No")

# set to a factor to store the results
attrClassPreds = factor(attrClassPreds, levels = c("Yes", "No"))

# View the results
summary(attrClassPreds)

compClassData$Attrition = attrClassPreds
compClassData$AttrBinPred = ifelse(attrCPreds >= .20, 1, 0)


compClassData %>% select(c("ID","Attrition")) %>% write.csv(file = "Case2PredictionsKunz Attritition.csv", row.names = FALSE)
```


For the Regression Model, a model using the variables with the highest positive correlations to MonthlyIncome were used for prediction. The majority of the fields used to build this model were related to time, as most jobs generally pay a premium for expertise and experience.

JobLevel: Numeric field. This is a scale of 1-5, with each level indicating a more advanced job. This field was the most highly correlated with MonthlyIncome. Highly skilled employees could likely be promoted to higher level jobs more quickly than peers of the same Age or with more years of working experience. The higher level jobs also generally paid more than lower level roles.
TotalWorkingYears: Numeric field. This field indicated the number of years of working experience each employee had. Experience likely had a higher correlation than age, because each record is representative of an individual person where they have various life circumstances that delay entry into the workforce or take them out of the workforce for a time.
Age: Numeric field. This field indicates the age of the employees. Most people generally receive raises each year of their lives; therefore, older workers will generally make more than their younger colleagues.
YearsAtCompany: Numeric field. The total years an individual has worked at the company.


```{r}
# Regression model to predict Salary

# Set iteration counter
iter = 100

# create a matrix to store the results
salMatrix = matrix(nrow = iter)

# Create Loop to measure across multiple iterations for model validation
for(s in 1:iter){ 
    # set seed to s generate replicable for each iteration to measure model performance
    set.seed(s)
      
    # Set training and test data sets for the data
    trainIndices = sample(seq(1:length(cs2data$Attrition)),round(.8*length(cs2data$Attrition)))
    trainData = cs2data[trainIndices,]
    testData = cs2data[-trainIndices,]
    
    # Create regression model using the test and training data
    salModel = lm(MonthlyIncome ~ JobLevel + TotalWorkingYears + Age + YearsAtCompany, data = trainData)
    salPreds = predict(salModel, newdata = testData)
    as.data.frame(salPreds)
    
    # Calculate RMSE
    RMSE = sqrt(mean(testData$MonthlyIncome - salPreds)^2)
    testData$salPreds = salPreds
    testData$salDelta = testData$MonthlyIncome - testData$salPreds
    
    # store RMSE into the matrix to compare results across iterations
    salMatrix[s] = RMSE
}
mean(salMatrix)

# use the model to predict the missing data
compSalPreds = predict(salModel, newdata = compSalData)

# add the predictions to the data frame
compSalData$MonthlyIncome = compSalPreds

# Export a selection of the data frame to a CSV
compSalData %>% select(c("ID","MonthlyIncome")) %>% write.csv(file = "Case2PredictionsKunz Salary.csv", row.names = FALSE)


```

Graphs for the Presentation

```{r}

#Create Scatter Plots to explore data relationships
compClassData %>% ggplot(aes(x = OverTime, y = JobInvolvement, color = Attrition)) + geom_point() + geom_jitter(width =.1, length = .1) + ggtitle("Attrition by Overtime and Job Involvement") + ggthemes::theme_economist_white() + xlab("Overtime Employee") + ylab("Job Involvement")

# Bar Chart to visualize Attrition as a percentage of Overtime
cs2data %>% ggplot(aes(x = OverTime, fill = Attrition)) + geom_bar() + ggtitle("Attrition by Overtime") + ggthemes::theme_economist_white() + xlab("Overtime Employee") + ylab("Employee Count") + geom_text(aes(label = sprintf("%d (%.1f%%)", ..count.., ..count.. / sum(..count..) * 100)), stat = "count", position = position_stack(vjust = 0.5), color = "black")

# Bar Chart to visualize Attrition as a percentage of Job Level
cs2data %>% ggplot(aes(x = JobLevel, fill = Attrition)) + geom_bar() + ggtitle("Attrition by Job Level") + ggthemes::theme_economist_white() + xlab("Employee Job Level") + ylab("Employee Count") + geom_text(aes(label = sprintf("%d (%.1f%%)", ..count.., ..count.. / sum(..count..) * 100)), stat = "count", position = position_stack(vjust = 0.5), color = "black")

cs2data$Under30 = ifelse(cs2data$U30 == 1, "Yes", "No")

# Bar Chart to visualize Attrition as a percentage of U30 Age
cs2data %>% ggplot(aes(x = Under30, fill = Attrition)) + geom_bar() + ggtitle("Attrition by Employees Under Age 30") + ggthemes::theme_economist_white() + xlab("Employee Under Age 30") + ylab("Employee Count") + geom_text(aes(label = sprintf("%d (%.1f%%)", ..count.., ..count.. / sum(..count..) * 100)), stat = "count", position = position_stack(vjust = 0.5), color = "black")

# Bar Chart to visualize Attrition related to Age
cs2data %>% ggplot(aes(x = Age, fill = Attrition)) + geom_bar() + geom_text(aes(label = sprintf("%d", ..count..)), stat = "count", position = position_stack(vjust = 0.5), color = "black") + ggtitle("Attrition by Employee Age") + ggthemes::theme_economist_white() + xlab("Employee Age") + ylab("Employee Count")

# Bar Chart to visualize Attrition as a percentage of Total Working Years
cs2data %>% ggplot(aes(x = JobInvolvement, fill = Attrition)) + geom_bar() + ggtitle("Attrition by Job Involvement") + ggthemes::theme_economist_white() + xlab("Employee Job Involvement") + ylab("Employee Count") + geom_text(aes(label = sprintf("%d", ..count..)), stat = "count", position = position_stack(vjust = 0.5), color = "black")

# Correlation between Age and JobLevel
sel = cs2data[,c("U30", "JobInvolvement")]
cor(sel)


#Performance Ratings and Attrition
cs2data %>% ggplot(aes(x = PerformanceRating, fill = Attrition)) + geom_bar() + ggtitle("Attrition by Performance Rating") + ggthemes::theme_economist_white() + xlab("Employee PerformanceRating") + ylab("Employee Count") + geom_text(aes(label = sprintf("%d", ..count..)), stat = "count", position = position_stack(vjust = 0.5), color = "black") 
```

